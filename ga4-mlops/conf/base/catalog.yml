# Here you can define all your data sets by using simple YAML syntax.
#
# Documentation for this file format can be found in "The Data Catalog"
# Link: https://kedro.readthedocs.io/en/stable/data/data_catalog.html

# COMMON SETTINGS

_raw_data_args: &raw_data_args
  type: pandas.GBQQueryDataSet
  project: gid-ml-framework
  layer: raw

_data_args: &data_args
  type: pandas.CSVDataSet
  save_args:
    index: False

_artifact_args: &artifact_args
  type: kedro_mlflow.io.artifacts.MlflowArtifactDataSet

_stored_modeling_artifacts_args: &stored_modeling_artifacts_args
  run_id: 291203b7f47145e4a41452859f4a3aeb

# RAW DATA

train.ga4_data:
  filepath: src/ga4_mlops/pipelines/data_preprocessing/sql/get_ga4_raw_data.sql
  load_args:
    configuration: {
      'query': {
        'parameterMode': 'NAMED',
        'queryParameters': [
            {
                'name': 'start_date',
                'parameterType': {'type': 'STRING'},
                'parameterValue': {'value': '20210126'}
            },
            {
                'name': 'end_date',
                'parameterType': {'type': 'STRING'},
                'parameterValue': {'value': '20210128'}
            },
            {
                'name': 'sample_size',
                'parameterType': {'type': 'INT64'},
                'parameterValue': {'value': 10000}
            }
        ]
      }
    }
    reauth: True
  <<: *raw_data_args
  

valid.ga4_data:
  filepath: src/ga4_mlops/pipelines/data_preprocessing/sql/get_ga4_raw_data.sql
  load_args:
    configuration: {
      'query': {
        'parameterMode': 'NAMED',
        'queryParameters': [
            {
                'name': 'start_date',
                'parameterType': {'type': 'STRING'},
                'parameterValue': {'value': '20210129'}
            },
            {
                'name': 'end_date',
                'parameterType': {'type': 'STRING'},
                'parameterValue': {'value': '20210129'}
            },
            {
                'name': 'sample_size',
                'parameterType': {'type': 'INT64'},
                'parameterValue': {'value': 2000}
            }
        ]
      }
    }
    reauth: True
  <<: *raw_data_args

test.ga4_data:
  filepath: src/ga4_mlops/pipelines/data_preprocessing/sql/get_ga4_raw_data.sql
  load_args:
    configuration: {
      'query': {
        'parameterMode': 'NAMED',
        'queryParameters': [
            {
                'name': 'start_date',
                'parameterType': {'type': 'STRING'},
                'parameterValue': {'value': '20210130'}
            },
            {
                'name': 'end_date',
                'parameterType': {'type': 'STRING'},
                'parameterValue': {'value': '20210130'}
            },
            {
                'name': 'sample_size',
                'parameterType': {'type': 'INT64'},
                'parameterValue': {'value': 2000}
            }
        ]
      }
    }
    
  <<: *raw_data_args

predict.ga4_data:
  filepath: src/ga4_mlops/pipelines/data_preprocessing/sql/get_ga4_raw_data.sql
  load_args:
    configuration: {
      'query': {
        'parameterMode': 'NAMED',
        'queryParameters': [
            {
                'name': 'start_date',
                'parameterType': {'type': 'STRING'},
                'parameterValue': {'value': '20210131'}
            },
            {
                'name': 'end_date',
                'parameterType': {'type': 'STRING'},
                'parameterValue': {'value': '20210131'}
            },
            {
                'name': 'sample_size',
                'parameterType': {'type': 'INT64'},
                'parameterValue': {'value': 2000}
            }
        ]
      }
    }
  <<: *raw_data_args

# PRIMARY DATA (AFTER: AFTER: SELECTION, AGGREGATION, SAMPLING)

train.df:
  filepath: data/03_primary/df_train.csv
  layer: primary
  <<: *data_args

valid.df:
  filepath: data/03_primary/df_valid.csv
  layer: primary
  <<: *data_args

test.df:
  filepath: data/03_primary/df_test.csv
  layer: primary
  <<: *data_args

predict.df:
  filepath: data/03_primary/df_predict.csv
  layer: primary
  <<: *data_args

# FEATURE DATA (AFTER: FEATURE ENGINEERING, IMPUTATION, ENCODING)

fitted.imputers:
  data_set:
    filepath: data/04_feature/imputers.pkl
    type: pickle.PickleDataSet
  <<: *artifact_args

stored.imputers:
  data_set:
    filepath: data/04_feature/imputers.pkl
    type: pickle.PickleDataSet
  <<: *stored_modeling_artifacts_args
  <<: *artifact_args

fitted.feature_encoders:
  data_set:
    filepath: data/04_feature/feature_encoders.pkl
    type: pickle.PickleDataSet
  <<: *artifact_args

stored.feature_encoders:
  data_set:
    filepath: data/04_feature/feature_encoders.pkl
    type: pickle.PickleDataSet
  <<: *stored_modeling_artifacts_args
  <<: *artifact_args

train.df_fe:
  filepath: data/04_feature/df_train_fe.csv
  layer: feature
  <<: *data_args

valid.df_fe:
  filepath: data/04_feature/df_valid_fe.csv
  layer: feature
  <<: *data_args

test.df_fe:
  filepath: data/04_feature/df_test_fe.csv
  layer: feature
  <<: *data_args

predict.df_fe:
  filepath: data/04_feature/df_predict_fe.csv
  layer: feature
  <<: *data_args

# MODEL INPUT DATA (AFTER: MANUAL FEATURE SELECTION)

train.abt:
  filepath: data/05_model_input/abt_train.csv
  layer: model_input
  <<: *data_args

valid.abt:
  type: pandas.CSVDataSet
  filepath: data/05_model_input/abt_valid.csv
  layer: model_input
  <<: *data_args

test.abt:
  filepath: data/05_model_input/abt_test.csv
  layer: model_input
  <<: *data_args

predict.abt:
  filepath: data/05_model_input/abt_predict.csv
  layer: model_input
  <<: *data_args

# MODELS

fitted.model:
  data_set:
    type: pickle.PickleDataSet
    filepath: data/06_models/model.pkl
  <<: *artifact_args

model_config:
  data_set:
    type: json.JSONDataSet
    filepath: data/06_models/model_config.json
  <<: *artifact_args

stored.model:
  data_set:
    type: pickle.PickleDataSet
    filepath: data/06_models/model.pkl
  <<: *stored_modeling_artifacts_args
  <<: *artifact_args

# MODEL OUTPUT

predictions:
  filepath: data/07_model_output/predictions.csv
  layer: model_output
  <<: *data_args

# REPORTING

train.shap_summary_plot:
  data_set:
    type: matplotlib.MatplotlibWriter
    filepath: data/08_reporting/train_shap_summary_plot.png
    save_args:
      format: png
  <<: *artifact_args

train.feature_importance:
  data_set:
    type: json.JSONDataSet
    filepath: data/08_reporting/train_feature_importance.json
  <<: *artifact_args

train.partial_dependence_plots:
  data_set:
    type: matplotlib.MatplotlibWriter
    filepath: data/08_reporting/train_partial_dependence_plots
    overwrite: True
    save_args:
      format: png
  <<: *artifact_args

valid.shap_summary_plot:
  data_set:
    type: matplotlib.MatplotlibWriter
    filepath: data/08_reporting/valid_shap_summary_plot.png
    save_args:
      format: png
  <<: *artifact_args

valid.feature_importance:
  data_set:
    type: json.JSONDataSet
    filepath: data/08_reporting/valid_feature_importance.json
  <<: *artifact_args

valid.partial_dependence_plots:
  data_set:
    type: matplotlib.MatplotlibWriter
    filepath: data/08_reporting/valid_partial_dependence_plots
    overwrite: True
    save_args:
      format: png
  <<: *artifact_args

test.shap_summary_plot:
  data_set:
    type: matplotlib.MatplotlibWriter
    filepath: data/08_reporting/test_shap_summary_plot.png
    save_args:
      format: png
  <<: *artifact_args

test.feature_importance:
  data_set:
    type: json.JSONDataSet
    filepath: data/08_reporting/test_feature_importance.json
  <<: *artifact_args

test.partial_dependence_plots:
  data_set:
    type: matplotlib.MatplotlibWriter
    filepath: data/08_reporting/test_partial_dependence_plots
    overwrite: True
    save_args:
      format: png
  <<: *artifact_args
